<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Heim's Syntrometric Theory & Live2D Agent Demo</title> <!-- Updated Title -->
    <!-- Google Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">

    <style>
        /* --- (CSS Styles remain the same, added hidden canvas style) --- */
        :root { /* ... CSS variables ... */
            --background-color: #111122; --text-color: #eeeeee; --container-background: #1e1e2a;
            --container-border-color: #333355; --accent-color: #00aaff; --link-hover-color: #66ccff;
            --viz-background: #111122; --info-panel-bg: rgba(40, 40, 60, 0.9); --info-panel-text: #eeeeee;
            --shadow-color: rgba(0, 0, 0, 0.5); --text-muted: #aaaaaa;
         }
        body { font-family: 'Inter', sans-serif; line-height: 1.7; margin: 0; overflow-x: hidden; background-color: var(--background-color); color: var(--text-color); font-size: 16px; }
        header { background: linear-gradient(135deg, #1f1f2f 0%, #2c2c3f 100%); color: var(--text-color); padding: 2rem 1rem; text-align: center; box-shadow: 0 2px 4px var(--shadow-color); }
        header h1 { margin: 0 0 0.5rem 0; font-weight: 700; font-size: 2.2rem; }
        header p { margin: 0; font-size: 1.1rem; color: var(--text-muted); }
        .container { max-width: 900px; margin: 2rem auto; padding: 2rem; background: var(--container-background); border-radius: 8px; border: 1px solid var(--container-border-color); box-shadow: 0 4px 12px var(--shadow-color); }
        h2 { color: var(--accent-color); margin-top: 0; margin-bottom: 1.5rem; font-weight: 600; border-bottom: 2px solid var(--accent-color); padding-bottom: 0.5rem; }
        h3 { color: var(--accent-color); margin-top: 1.5rem; margin-bottom: 1rem; font-weight: 600; }
        p { margin: 0 0 1rem 0; }
        a { color: var(--accent-color); text-decoration: none; font-weight: 600; transition: color 0.3s ease; }
        a:hover, a:focus { color: var(--link-hover-color); text-decoration: underline; }
        ul { list-style: none; padding-left: 0; }
        li { margin-bottom: 0.75rem; position: relative; padding-left: 1.5rem; }
        li::before { content: 'â†’'; position: absolute; left: 0; color: var(--accent-color); font-weight: bold; }
        .quick-links-list li::before { content: 'ðŸ”—'; }
        .threejs-container { width: 100%; height: 650px; margin: 2rem 0; background-color: var(--viz-background); position: relative; border-radius: 8px; overflow: hidden; border: 1px solid var(--container-border-color); box-shadow: inset 0 0 10px var(--shadow-color); }
        canvas { display: block; }
        .label { color: #fff; font-family: 'Inter', sans-serif; padding: 3px 6px; background: rgba(0, 0, 0, 0.7); border-radius: 4px; font-size: 11px; font-weight: 600; pointer-events: none; user-select: none; white-space: nowrap; position: absolute; text-shadow: 1px 1px 2px rgba(0,0,0,0.5); transform: translate(-50%, 0); }
        #info-panel { position: absolute; top: 15px; left: 15px; background-color: var(--info-panel-bg); color: var(--info-panel-text); padding: 12px 18px; border-radius: 6px; max-width: 300px; font-size: 13px; border: 1px solid var(--container-border-color); box-shadow: 0 2px 10px var(--shadow-color); z-index: 10; pointer-events: none; backdrop-filter: blur(3px); transition: opacity 0.2s ease-in-out; opacity: 1; }
        #info-panel:empty { opacity: 0; }
        #info-panel h3 { margin: 0 0 8px 0; color: var(--accent-color); font-size: 15px; font-weight: 700; border-bottom: 1px solid rgba(255, 255, 255, 0.15); padding-bottom: 6px; }
        #info-panel p { margin: 4px 0; line-height: 1.5; }
        #info-panel p b { color: #aaaaff; font-weight: 600; margin-right: 5px; }
        #info-panel .links-list { margin-top: 8px; padding-top: 6px; border-top: 1px solid rgba(255, 255, 255, 0.1); font-size: 12px; color: #cccccc; }
        #info-panel .links-list b { color: #aaccaa; }
        #info-panel .simulated-data { color: #ffcc66; font-style: italic; font-size: 12px; }

        /* Style to hide the PixiJS canvas used for texture generation */
        #live2d-offscreen-canvas {
            position: absolute;
            top: -9999px; /* Move off-screen */
            left: -9999px;
            width: 512px; /* Needs a defined size for rendering */
            height: 512px;
            opacity: 0; /* Make invisible */
            pointer-events: none; /* Prevent interaction */
        }

    </style>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.164.1/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.164.1/examples/jsm/",
                 "pixi.js": "https://unpkg.com/pixi.js@7/dist/pixi.min.js",
                 "pixi-live2d-display": "https://unpkg.com/pixi-live2d-display@0.4.0/dist/index.min.js"
            }
        }
    </script>
</head>
<body>
    <header>
        <h1>Heim's Syntrometric Theory Visualization & Live2D Agent Demo</h1>
        <p>Explore Burkhard Heim's unified field theory and a conceptual demo of an integrated AI agent with Live2D.</p>
    </header>

    <div class="container">
         <h2>About Syntrometric Theory</h2>
         <p>Burkhard Heim's Syntrometric Theory describes reality as a 12-dimensional quantized system, integrating physics and consciousness. Key concepts include the Syntrix, Metrons, Dimensions (R1-R12), Strukturkaskaden, and Telezentrik.</p>
         <h3>Quick Links</h3>
         <ul class="quick-links-list">
             <li><a href="research/syntrometrie_framework.html" title="View 2D Diagram">Syntrometrie Framework Diagram</a></li>
             <li><a href="research/conscious_agent_arch.html" title="View Agent Architecture">Conscious Agent Architecture Diagram</a></li>
             <li><a href="../README.md" title="Go to Main Project Readme">Main Project README</a></li>
             <li><a href="https://heim-theory.com/" target="_blank" title="External Resource (Opens New Tab)">Heim Theory Resources</a></li>
         </ul>
    </div>

    <div class="container">
        <h2>Interactive 3D Model & Live2D Agent Demo</h2>
        <p>The visualization shows Syntrometric concepts and integrates a Live2D avatar placeholder. The agent's simulated internal state influences the avatar's parameters and an "Emergence Core". Hover for details. Use mouse/touch to explore.</p>
        <div class="threejs-container">
            <div id="info-panel"></div>
            <!-- Hidden canvas for PixiJS/Live2D rendering -->
            <canvas id="live2d-offscreen-canvas"></canvas>
        </div>
    </div>

    <!-- === START OF JAVASCRIPT MODULE === -->
    <script type="module">
        import * as THREE from 'three';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
        import { CSS2DRenderer, CSS2DObject } from 'three/addons/renderers/CSS2DRenderer.js';
        // --- Import PixiJS and Live2D Display ---
        import * as PIXI from 'pixi.js';
        import { Live2DModel } from 'pixi-live2d-display';
        // Expose PIXI globally for the Live2D display plugin (required by some versions)
        window.PIXI = PIXI;

        // --- Global Variables ---
        let scene, camera, renderer, labelRenderer, controls;
        let raycaster, mouse;
        let infoPanel;
        const nodes = {};
        const edges = [];
        let container;
        let clock;

        // --- Simulation Placeholders ---
        let agentStateMesh, emergenceCoreMesh; // AvatarMesh replaced by live2dPlane
        let agentStateLabel, emergenceCoreLabel; // AvatarLabel replaced
        const simulatedEmotions = new THREE.Vector3(0.5, 0.5, 0.5);
        let simulatedPrevEmotions = simulatedEmotions.clone();
        let simulatedIntegration = 0.5;
        let simulatedReflexivity = 0.5;
        const RHO_THRESHOLD = 0.8;
        let simulatedThreshold = 0.6;
        let emergenceActive = false;

        // --- Live2D / PixiJS Variables ---
        let pixiApp;
        let live2dModel;
        let live2dPlane; // The THREE.js plane that will display the Live2D model
        let live2dTexture; // The THREE.js texture linked to the PixiJS canvas

        let interactableObjects = [];

        // --- Concept Data ---
        const conceptData = { /* ... (same concept data as before) ... */
            'reflexive_abstraction': { id: 'reflexive_abstraction', name: 'Reflexive Abstraktion', chapter: 1, position: new THREE.Vector3(0, 15, -20), type: 'method', links: ['syntrometry'], description: "Method..." },
            'subjective_aspect': { id: 'subjective_aspect', name: 'Subjective Aspect (S)', chapter: 1, position: new THREE.Vector3(-10, 10, -18), type: 'structure', links: ['pradikatrix', 'dialektik', 'koordination', 'aspektivsystem'], description: "Contextual framework..." },
            'pradikatrix': { id: 'pradikatrix', name: 'PrÃ¤dikatrix (Pm)', chapter: 1, position: new THREE.Vector3(-20, 15, -16), type: 'component', links: [], description: "Schema..." },
            'dialektik': { id: 'dialektik', name: 'Dialektik (Dn)', chapter: 1, position: new THREE.Vector3(-15, 15, -16), type: 'component', links: [], description: "Schema..." },
            'koordination': { id: 'koordination', name: 'Koordination (Kn)', chapter: 1, position: new THREE.Vector3(-10, 15, -16), type: 'component', links: [], description: "Mechanism..." },
            'aspektivsystem': { id: 'aspektivsystem', name: 'Aspektivsystem (P)', chapter: 1, position: new THREE.Vector3(10, 10, -18), type: 'structure', links: ['metropie', 'idee'], description: "Collection..." },
            'metropie': { id: 'metropie', name: 'Metropie (g)', chapter: 1, position: new THREE.Vector3(20, 15, -16), type: 'property', links: [], description: "Metric..." },
            'idee': { id: 'idee', name: 'Idee (Apodiktic Core)', chapter: 1, position: new THREE.Vector3(15, 5, -16), type: 'core', links: [], description: "Invariant..." },
            'syntrometry': { id: 'syntrometry', name: 'Syntrometrie', chapter: 1, position: new THREE.Vector3(0, 0, -18), type: 'framework', links: ['syntrix'], description: "Heim's logic..." },
            'syntrix': { id: 'syntrix', name: 'Syntrix (Ã£|=)', chapter: 2, position: new THREE.Vector3(0, 0, -10), type: 'structure', links: ['metrophor', 'synkolator', 'synkolation_stage', 'korporator'], description: "Formal structure..." },
            'metrophor': { id: 'metrophor', name: 'Metrophor (Ã£)', chapter: 2, position: new THREE.Vector3(-10, 5, -8), type: 'core', links: ['idee'], description: "Invariant core..." },
            'synkolator': { id: 'synkolator', name: 'Synkolator ({)', chapter: 2, position: new THREE.Vector3(0, 5, -8), type: 'operator', links: [], description: "Correlation law..." },
            'synkolation_stage': { id: 'synkolation_stage', name: 'Synkolation Stage (m)', chapter: 2, position: new THREE.Vector3(10, 5, -8), type: 'parameter', links: [], description: "Arity/depth..." },
            'korporator': { id: 'korporator', name: 'Korporator ({})', chapter: 3, position: new THREE.Vector3(0, -5, -5), type: 'operator', links: ['syntrix'], description: "Combining operator..." },
        };

        // --- Initialization Function --- *** MODIFIED ***
        async function init() { // Make init async to handle Live2D model loading
            container = document.querySelector('.threejs-container');
            infoPanel = document.getElementById('info-panel');
            if (!container) { console.error("Container not found"); return; }
            if (infoPanel) infoPanel.innerHTML = ''; else console.warn("Info panel not found.");

            clock = new THREE.Clock();

            const width = container.clientWidth;
            const height = container.clientHeight;

            // --- Three.js Setup ---
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x111122);
            scene.fog = new THREE.Fog(0x111122, 60, 160);
            camera = new THREE.PerspectiveCamera(65, width / height, 0.1, 1000);
            camera.position.set(0, 15, 55);
            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true }); // Use alpha for potential transparency
            renderer.setSize(width, height);
            renderer.setPixelRatio(window.devicePixelRatio);
            container.appendChild(renderer.domElement);
            labelRenderer = new CSS2DRenderer();
            labelRenderer.setSize(width, height);
            labelRenderer.domElement.style.position = 'absolute';
            labelRenderer.domElement.style.top = '0px';
            labelRenderer.domElement.style.left = '0px';
            labelRenderer.domElement.style.pointerEvents = 'none';
            container.appendChild(labelRenderer.domElement);
            controls = new OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true; controls.dampingFactor = 0.05;
            controls.minDistance = 10; controls.maxDistance = 150;
            controls.target.set(0, 5, -10); controls.update();
            const ambientLight = new THREE.AmbientLight(0x8080a0); // Slightly more ambient
            scene.add(ambientLight);
            const dirLight1 = new THREE.DirectionalLight(0xffffff, 1.0); // Brighter main
            dirLight1.position.set(5, 10, 7).normalize(); scene.add(dirLight1);
            const dirLight2 = new THREE.DirectionalLight(0xaaaaff, 0.5);
            dirLight2.position.set(-5, -5, -5).normalize(); scene.add(dirLight2);

            // --- PixiJS & Live2D Setup ---
            try {
                const offscreenCanvas = document.getElementById('live2d-offscreen-canvas');
                pixiApp = new PIXI.Application({
                    view: offscreenCanvas,
                    width: 512, // Texture resolution
                    height: 512,
                    transparent: true, // Render with transparent background
                    autoStart: false, // We'll manually update
                    preserveDrawingBuffer: true, // Needed for CanvasTexture? Sometimes.
                });

                // --- !!! IMPORTANT: REPLACE WITH YOUR MODEL PATH !!! ---
                const modelPath = 'https://github.com/Marko0Marky/Live2d-Avatar-Ai/blob/Advanced_VTuber_AI/models/as01.model3.json'; // Example path - CHANGE THIS
                // --- !!! IMPORTANT: REPLACE WITH YOUR MODEL PATH !!! ---

                console.log(`Attempting to load Live2D model from: ${modelPath}`);
                live2dModel = await Live2DModel.from(modelPath, { autoInteract: false }); // Load model using pixi-live2d-display
                console.log("Live2D model loaded successfully.");

                // Scale and position the model within the PixiJS stage
                live2dModel.scale.set(0.15); // Adjust scale as needed
                 // Center the model roughly - may need fine-tuning based on model anchor
                 live2dModel.x = pixiApp.screen.width / 2;
                 live2dModel.y = pixiApp.screen.height / 1.5;
                 live2dModel.anchor.set(0.5, 0.5); // Set anchor to center

                pixiApp.stage.addChild(live2dModel); // Add model to Pixi stage

                // --- Create Three.js Plane and Texture ---
                live2dTexture = new THREE.CanvasTexture(pixiApp.view); // Create texture from Pixi's canvas
                live2dTexture.premultiplyAlpha = true; // Important for correct blending

                const planeHeight = 10; // Adjust size of the plane in Three.js scene
                const planeWidth = planeHeight * (pixiApp.screen.width / pixiApp.screen.height);
                const planeGeo = new THREE.PlaneGeometry(planeWidth, planeHeight);
                const planeMat = new THREE.MeshBasicMaterial({ // Use MeshBasicMaterial for unlit texture
                    map: live2dTexture,
                    transparent: true, // Enable transparency
                    side: THREE.DoubleSide, // Render both sides
                     alphaTest: 0.1 // Optional: help with sharp edges
                });
                live2dPlane = new THREE.Mesh(planeGeo, planeMat);
                live2dPlane.position.set(0, -10, 0); // Position where avatar placeholder was
                live2dPlane.userData = { type: 'live2d_avatar', name: "Live2D Avatar" };
                scene.add(live2dPlane);
                console.log("Three.js plane created for Live2D texture.");

            } catch (error) {
                console.error("Failed to initialize PixiJS or load Live2D model:", error);
                alert(`Failed to load Live2D model: ${error}\nCheck model path and browser console.`);
                // Optionally add a fallback placeholder if Live2D fails
                 const fallbackGeo = new THREE.BoxGeometry(3, 5, 1);
                 const fallbackMat = new THREE.MeshStandardMaterial({color: 0xff0000, roughness: 0.8});
                 live2dPlane = new THREE.Mesh(fallbackGeo, fallbackMat);
                 live2dPlane.position.set(0, -10, 0);
                 live2dPlane.userData = { type: 'error_placeholder', name: "Live2D Load Failed" };
                 scene.add(live2dPlane);
            }

            // --- Create Original Graph & Other Placeholders ---
            createNodes();
            createEdges();
            createAgentSimulationPlaceholders(); // Will now skip avatar mesh creation

            // --- Final Setup ---
            interactableObjects = Object.values(nodes).map(n => n.object);
            if (agentStateMesh) interactableObjects.push(agentStateMesh);
            if (live2dPlane) interactableObjects.push(live2dPlane); // Add Live2D plane
            if (emergenceCoreMesh) interactableObjects.push(emergenceCoreMesh);

            setupInteraction();
            window.addEventListener('resize', onWindowResize, false);
            animate(); // Start animation loop
        }

        // --- Node/Edge Creation (Unchanged) ---
        function createNodes() { /* ... same as before ... */ console.log(`Created ${Object.keys(nodes).length} concept nodes.`); }
        function createEdges() { /* ... same as before ... */ console.log(`Created ${edges.length} edges.`); }

        // --- Create Simulation Placeholders --- *** MODIFIED ***
        function createAgentSimulationPlaceholders() {
            const placeholderY = -15;

            // 1. Agent Internal State Placeholder (Unchanged)
            const agentStateGeo = new THREE.SphereGeometry(2.5, 32, 16);
            const agentStateMat = new THREE.MeshPhongMaterial({ color: 0xaaaaaa, shininess: 60, transparent: true, opacity: 0.8 });
            agentStateMesh = new THREE.Mesh(agentStateGeo, agentStateMat);
            agentStateMesh.position.set(-15, placeholderY, -5);
            agentStateMesh.userData = { type: 'agent_state', name: "Agent Internal State" };
            scene.add(agentStateMesh);
            agentStateLabel = createPlaceholderLabel("Agent State", agentStateMesh, 3.0);

            // 2. Avatar Representation Placeholder -> SKIPPED (replaced by live2dPlane)
            // console.log("Skipping avatar placeholder creation, Live2D will be used.");

            // 3. Emergence/RIH Core Placeholder (Unchanged)
            const emergenceGeo = new THREE.IcosahedronGeometry(1.8, 1);
            const emergenceMat = new THREE.MeshPhongMaterial({ color: 0xffcc00, emissive: 0x000000, shininess: 80, transparent: true, opacity: 0.6 });
            emergenceCoreMesh = new THREE.Mesh(emergenceGeo, emergenceMat);
            emergenceCoreMesh.position.set(15, placeholderY, -5);
            emergenceCoreMesh.userData = { type: 'emergence_core', name: "Emergence Core (RIH)" };
            scene.add(emergenceCoreMesh);
            emergenceCoreLabel = createPlaceholderLabel("Emergence Core", emergenceCoreMesh, 2.5);

            console.log("Created simulation placeholder objects (excluding avatar).");
        }
        function createPlaceholderLabel(text, parentMesh, yOffset) { /* ... same as before ... */ const labelDiv = document.createElement('div'); labelDiv.className = 'label'; labelDiv.textContent = text; labelDiv.style.fontSize = '13px'; labelDiv.style.fontWeight = 'bold'; const labelObj = new CSS2DObject(labelDiv); labelObj.position.set(0, yOffset, 0); parentMesh.add(labelObj); return labelObj; }

        // --- Interaction Setup (Unchanged) ---
        function setupInteraction() { /* ... same as before ... */ raycaster = new THREE.Raycaster(); mouse = new THREE.Vector2(); if (container) { container.addEventListener('mousemove', onPointerMove, false); container.addEventListener('touchmove', onPointerMove, { passive: false }); container.addEventListener('touchend', onPointerUp, false); container.addEventListener('mouseleave', onPointerLeave, false); } }
        let lastIntersected = null;
        function onPointerMove(event) { /* ... same as before ... */ let clientX, clientY; if (event.touches && event.touches.length>0){ clientX=event.touches[0].clientX; clientY=event.touches[0].clientY; event.preventDefault(); } else { clientX=event.clientX; clientY=event.clientY; } updatePointerPosition(clientX, clientY); checkIntersections(); }
        function onPointerUp(event) { if (event.changedTouches) clearHover(); }
        function onPointerLeave(event) { clearHover(); }
        function updatePointerPosition(clientX, clientY) { /* ... same as before ... */ if (!container) return; const rect = container.getBoundingClientRect(); mouse.x = ((clientX - rect.left) / rect.width) * 2 - 1; mouse.y = -((clientY - rect.top) / rect.height) * 2 + 1; }
        function checkIntersections() { /* ... (same as previous - checks interactableObjects) ... */ if (!camera || !raycaster || interactableObjects.length === 0) return; raycaster.setFromCamera(mouse, camera); const intersects = raycaster.intersectObjects(interactableObjects, false); if (intersects.length > 0) { const intersectedObject = intersects[0].object; if (intersectedObject !== lastIntersected) { updateInfoPanel(intersectedObject); lastIntersected = intersectedObject; } } else { clearHover(); } }

        // --- Update Info Panel Helper --- *** MODIFIED ***
        function updateInfoPanel(nodeMesh) {
             if (!infoPanel) return;
             const userData = nodeMesh.userData;
             if (!userData || !userData.type) { infoPanel.innerHTML = ''; return; }
             let panelHtml = '';
             const safeName = (userData.name || 'Unnamed Object').replace(/</g, "<").replace(/>/g, ">");

             switch(userData.type) {
                 case 'concept':
                    // ... (same concept display logic as before) ...
                    const data = userData.data; let linksHtml = ''; if (data.links && data.links.length > 0) { const linkedNames = data.links.map(id => conceptData[id]?.name).filter(n=>n).map(n=>n.replace(/</g, "<").replace(/>/g, ">")); if (linkedNames.length > 0) linksHtml = `<div class="links-list"><b>Links To:</b> ${linkedNames.join(', ')}</div>`; } panelHtml = `<h3>${safeName}</h3> ${data.type ? `<p><b>Type:</b> ${data.type}</p>` : ''} ${data.chapter ? `<p><b>Chapter:</b> ${data.chapter}</p>` : ''} ${data.description ? `<p><b>Desc:</b> ${data.description}</p>` : ''} ${linksHtml}`;
                    break;
                 case 'agent_state':
                    const emoStr = `[V: ${simulatedEmotions.x.toFixed(2)}, A: ${simulatedEmotions.y.toFixed(2)}, D: ${simulatedEmotions.z.toFixed(2)}]`; panelHtml = `<h3>${safeName}</h3> <p class="simulated-data">Represents the AI's internal emotional state.</p> <p><b>Simulated Emotions:</b> ${emoStr}</p>`;
                    break;
                 case 'live2d_avatar': // Updated type
                    panelHtml = `<h3>${safeName}</h3> <p class="simulated-data">Live2D model driven by simulated agent state.</p> <p><b>(Parameters reflect agent's simulated emotion)</b></p>`;
                    break;
                 case 'emergence_core':
                    // ... (same emergence display logic as before) ...
                    const rihState = emergenceActive ? 'Met (Glowing)' : 'Not Met'; panelHtml = `<h3>${safeName}</h3> <p class="simulated-data">Represents RIH-based emergence.</p> <p><b>Simulated I:</b> ${simulatedIntegration.toFixed(3)}</p> <p><b>Simulated Rho:</b> ${simulatedReflexivity.toFixed(3)} (Threshold: ${RHO_THRESHOLD.toFixed(2)})</p> <p><b>Simulated Tau(t):</b> ${simulatedThreshold.toFixed(3)}</p> <p><b>Emergence State:</b> ${rihState}</p>`;
                    break;
                 default:
                    panelHtml = `<h3>${safeName}</h3><p>Unknown object type.</p>`;
             }
             infoPanel.innerHTML = panelHtml;
         }

        function clearHover() { /* ... same as before ... */ if (lastIntersected) lastIntersected = null; if (infoPanel) infoPanel.innerHTML = ''; }

        // --- Simple Simulation Update --- *** MODIFIED ***
        function updateSimulationStep(deltaTime) {
             // Update original placeholders (Agent State, Emergence Core)
             if (agentStateMesh) { /* ... (update agent state mesh visuals based on simulatedEmotions/Integration) ... */
                 agentStateMesh.material.color.setRGB(simulatedEmotions.x, simulatedEmotions.y, simulatedEmotions.z);
                 agentStateMesh.material.opacity = 0.6 + simulatedIntegration * 0.4;
             }
             if (emergenceCoreMesh) { /* ... (update emergence core visuals based on emergenceActive) ... */
                 if (emergenceActive) { emergenceCoreMesh.material.emissive.setHex(0xffcc00); emergenceCoreMesh.material.opacity = 0.9; emergenceCoreMesh.scale.setScalar(1.0 + Math.sin(clock.getElapsedTime() * 5.0) * 0.1); } else { emergenceCoreMesh.material.emissive.setHex(0x000000); emergenceCoreMesh.material.opacity = 0.6; emergenceCoreMesh.scale.setScalar(1.0); }
             }

            // --- Update Live2D Model Parameters ---
            if (live2dModel && live2dModel.internalModel && live2dModel.internalModel.coreModel) {
                const coreModel = live2dModel.internalModel.coreModel;
                // Simple mapping: Emotion X -> Head/Body Angle X, Emotion Y -> Eye Open/Blink, Emotion Z -> Breath
                const targetAngleX = (simulatedEmotions.x - 0.5) * 60; // Map V [-30, 30]
                const targetEyeOpen = simulatedEmotions.y; // Map A [0, 1]
                const targetBreath = simulatedEmotions.z; // Map D [0, 1]

                // Smooth parameter updates (optional, Live2D physics might handle some)
                 const smoothing = 1.0 - Math.exp(-deltaTime / 0.1); // Adjust time constant (0.1s here)

                 // Function to safely set parameter, applying smoothing
                 const setParam = (id, targetValue, isAngle = false) => {
                     try {
                         let currentVal = coreModel.getParameterValueById(id);
                         let smoothedVal = currentVal + (targetValue - currentVal) * smoothing;
                         // Clamp based on heuristics if needed
                         if (id.includes('Eye') || id.includes('Breath')) smoothedVal = Math.max(0, Math.min(1, smoothedVal));
                         if (isAngle) smoothedVal = Math.max(-30, Math.min(30, smoothedVal)); // Rough angle clamp
                         coreModel.setParameterValueById(id, smoothedVal);
                     } catch (e) { /*console.warn(`Could not set param ${id}: ${e}`);*/ } // Avoid console spam
                 };

                // Apply parameters (Use standard Cubism IDs)
                 setParam('ParamAngleX', targetAngleX, true);
                 setParam('ParamBodyAngleX', targetAngleX * 0.5, true); // Body follows head less
                 setParam('ParamEyeLOpen', targetEyeOpen);
                 setParam('ParamEyeROpen', targetEyeOpen);
                 setParam('ParamBreath', targetBreath);
                 // Add more parameters as needed (e.g., Mouth, Brow) mapped from emotions
                 setParam('ParamMouthOpenY', Math.abs(simulatedEmotions.x - 0.5) * 0.5); // Example: Mouth opens slightly with stronger valence
            }

            // --- Update Base Simulation Values (Emotions, Metrics) ---
            // (This logic remains the same as before)
            simulatedPrevEmotions.copy(simulatedEmotions);
            const decay = 0.995; const noiseScale = 0.05;
            simulatedEmotions.x = (simulatedEmotions.x - 0.5) * decay + 0.5 + (Math.random() - 0.5) * noiseScale;
            simulatedEmotions.y = (simulatedEmotions.y - 0.5) * decay + 0.5 + (Math.random() - 0.5) * noiseScale;
            simulatedEmotions.z = (simulatedEmotions.z - 0.5) * decay + 0.5 + (Math.random() - 0.5) * noiseScale;
            simulatedEmotions.clampScalar(0.0, 1.0);
            simulatedIntegration = (simulatedEmotions.x + simulatedEmotions.y + simulatedEmotions.z) / 3.0;
            const dot = simulatedEmotions.dot(simulatedPrevEmotions); const lenSq1 = simulatedEmotions.lengthSq(); const lenSq2 = simulatedPrevEmotions.lengthSq();
            simulatedReflexivity = (lenSq1 > 1e-6 && lenSq2 > 1e-6) ? dot / Math.sqrt(lenSq1 * lenSq2) : 1.0;
            const emotionVariance = simulatedEmotions.clone().subScalar(simulatedIntegration).lengthSq() / 3.0; const stabilityProxy = 1.0 - Math.min(1.0, emotionVariance * 5.0);
            simulatedThreshold = 0.5 + stabilityProxy * 0.2 - simulatedIntegration * 0.1; simulatedThreshold = Math.max(0.1, Math.min(0.9, simulatedThreshold));
            emergenceActive = (simulatedIntegration >= simulatedThreshold) && (simulatedReflexivity >= RHO_THRESHOLD);
        }


        // --- Animation Loop --- *** MODIFIED ***
        function animate() {
            requestAnimationFrame(animate);
            const deltaTime = clock.getDelta();

            // 1. Update the simple simulation state
            updateSimulationStep(deltaTime);

            // 2. Update PixiJS/Live2D
            if (pixiApp && live2dModel && live2dTexture) {
                // Update the Live2D model's internal state (applies physics, etc.)
                // Note: pixi-live2d-display v0.4 might need update method called explicitly
                // Check the specific library version's API if model doesn't animate
                 if (typeof live2dModel.update === 'function') {
                     live2dModel.update(deltaTime); // Pass delta time if required by API
                 }

                // Render the PixiJS stage to its canvas
                 pixiApp.renderer.render(pixiApp.stage);

                // IMPORTANT: Update the Three.js texture from the canvas
                live2dTexture.needsUpdate = true;
            }

            // 3. Update Three.js Controls & Renderers
            if (controls && controls.enabled) controls.update();
            if (renderer && scene && camera) renderer.render(scene, camera);
            if (labelRenderer && scene && camera) labelRenderer.render(scene, camera);
        }

        // --- Resize Handler --- *** MODIFIED ***
        function onWindowResize() {
             if (!container || !camera || !renderer || !labelRenderer) return;
             const width = container.clientWidth;
             const height = container.clientHeight;
             camera.aspect = width / height; camera.updateProjectionMatrix();
             renderer.setSize(width, height); labelRenderer.setSize(width, height);
             // Note: Resizing the offscreen PixiJS canvas might be needed if
             // its resolution significantly affects quality on the plane,
             // but keeping it fixed simplifies things for now.
         }

        // --- Start Application After DOM Loaded ---
        document.addEventListener('DOMContentLoaded', () => {
            console.log("DOM ready, initializing Heim Theory + Live2D Demo...");
            init().catch(error => { // Catch errors from async init
                 console.error("Initialization failed:", error);
                 const errContainer = document.querySelector('.threejs-container') || document.body;
                 errContainer.innerHTML = `<div style="color: #ff4444; background-color: #2a1e2a; border: 1px solid #553355; padding: 1rem; border-radius: 6px; text-align: center; font-weight: bold;">Error initializing 3D visualization: ${error.message}<br>Check console for details.</div>`;
                 if (infoPanel) infoPanel.style.display = 'none';
             });
        });
    </script>
    <!-- === END OF JAVASCRIPT MODULE === -->

</body>
</html>
